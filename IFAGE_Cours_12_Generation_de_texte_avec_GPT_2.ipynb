{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ochekroun/labs/blob/master/IFAGE_Cours_12_Generation_de_texte_avec_GPT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMDQXhaVkFzM"
      },
      "source": [
        "# Génération de texte avec GPT2 et KerasNLP\n",
        "\n",
        "Adapté de https://keras.io/examples/generative/gpt2_text_generation_with_kerasnlp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPanjW8AkFzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baec5fef-eb56-434f-fff3-5ca2ee12385c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# On install KerasNLP, l'extension pour le traitement de langue de Keras\n",
        "!pip install git+https://github.com/keras-team/keras-nlp.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfks_f0GkFzP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "# Permets de réduire l'utilisation de mémoire\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On utilise des contextes de 128 tokens au lieu de 1024 pour accélérer l'utilisation du modèle\n",
        "# (au prix d'une taille de contexte plus limitée)\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "\n",
        "# On télécharge le plus petit model GPT-2, qui a 124.44M paramètres\n",
        "# Voir https://keras.io/api/keras_nlp/models/gpt2/gpt2_causal_lm/\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\"\n",
        "    #\"gpt2_medium_en\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB9spLgouA5S",
        "outputId": "3af3d971-8647-4f75-af8c-7a72e41db659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/preprocessor.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/task.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/2/download/preprocessor.json...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsiH9UHgkFzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1510ab2b-76a7-44ce-9ad2-603ff263ae73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"My trip to Switzerland was very interesting, but I'm sure you've noticed the same thing. I was there to see the world and see what was going on around them. I didn't have the time to see the world, so I didn't get to see the people I was looking to see and the people who I wanted to see.\\n\\nThe tour was a little more difficult. I had some time to think about the world before I even started. I had some time to think about my life before I actually got here. I had to be able to see what was going on and see what was happening. I had\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "gpt2_lm.generate(\"My trip to Switzerland was\", max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn0Y1SyykFzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8e2d8186-3e1a-4e64-809e-a161ed042c27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ce restaurant italien estancias en la vida.\\n\\nLa vez que se pueda en una ciabana, que esta una ciabana en una ciabana en una ciabana en una ciabana,\\n\\nCe ciabana estancias estancias en la vida.\\n\\nLa vida estancias estancias esse una ciabana.\\n\\nPuerto de una ciabana en una ciabana en un'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "gpt2_lm.generate(\"Ce restaurant italien est\", max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.generate(\"\", max_length=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HUA0SIEg4Fzb",
        "outputId": "03e50c18-9809-4ab6-cb9e-f127838060f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe first of the two-part documentary series, \"The New York Times Best Seller, \" examines the impact of the housing crisis on the American economy. In this first episode, \"The Times\\' David Sirota and I look into the impact of the housing crisis on the American economy and the role the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.generate(\"List of countries and their capitals:Russia: Moscow, Switzerland: Bern, Finland:\", max_length=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JU6zBoZnumAu",
        "outputId": "f6300c25-36b3-41a6-b68c-27a59af96f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'List of countries and their capitals:Russia: Moscow, Switzerland: Bern, Finland: Helsinki, Germany: Berlin, Hong Kong, New Zealand: Wellington,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFnfAqBbkFzQ"
      },
      "source": [
        "## Apprentissage par transfert (\"finetuning\") de GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFI_7vLskFzQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "math_qa = tfds.load(\"math_qa\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRQW7BBDkFzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55a238c-b0cf-43b9-cb4d-ddcb803e4830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'pascal has 96 miles remaining to complete his cycling trip . if he reduced his current speed by 4 miles per hour , the remainder of the trip would take him 16 hours longer than it would if he increased his speed by 50 % . what is his current speed w ?', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for document in math_qa:\n",
        "    print(document['Problem'])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSpVOAQekFzR"
      },
      "source": [
        "In our case, we are performing next word prediction in a language model, so we\n",
        "only need the 'document' feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5zFCStFkFzR"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    math_qa.map(lambda document: document['Problem'])\n",
        "    .batch(4)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmrY5N0nkFzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186b1e0e-ffb4-4fc5-c11a-b0fdd0b24ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.2601 - loss: 0.1687 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ecc446faa70>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_ds = train_ds.take(100)\n",
        "num_epochs = 1\n",
        "\n",
        "# Linearly decaying learning rate.\n",
        "#learning_rate = keras.optimizers.schedules.PolynomialDecay(\n",
        "#    5e-5,\n",
        "#    decay_steps=train_ds.cardinality() * num_epochs,\n",
        "#    end_learning_rate=0.0,\n",
        "#)\n",
        "#loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "gpt2_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "gpt2_lm.fit(train_ds, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.generate(\"\", max_length=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FA82Qk7b4V7w",
        "outputId": "fd553067-d83d-456a-dd71-3ef31d40fbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a train is running at 60 kmph with its speed of 60 kmph . what is the least amount the train will be required to pass a man who is running at 60 mph ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERRLM-XjkFzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5dd7a1-a4e7-465e-9e55-5b3431126b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If a circle is cut by 50 cm , the radius of a circle is reduced by 5 km . what is the area of the triangle ?\n"
          ]
        }
      ],
      "source": [
        "print(gpt2_lm.generate(\"If a circle\", max_length=128))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choix du prochain token : top-k"
      ],
      "metadata": {
        "id": "fnxWQa414pwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.compile(sampler=keras_nlp.samplers.TopKSampler(k=5))\n",
        "print(gpt2_lm.generate(\"I like basketball\", max_length=128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-zgB1it4yEr",
        "outputId": "f981fbce-d5ff-4420-a32a-119422bb87fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like basketball and is a team of the NBA team is going to win 5 points . if a team is playing at 5 - inch and the team is playing at 5 - inch , what is the greatest possible probability that the team can play at 5 - inch ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.compile(sampler=keras_nlp.samplers.TopKSampler(k=5))\n",
        "print(gpt2_lm.generate(\"I like basketball\", max_length=128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yscS43jM5Ae3",
        "outputId": "d87eaa8d-2959-4578-d6b8-9d1fa8d1c353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like basketball at a certain team , the team will have a winning streak of 5 . the team will be the same team will be the team that will be played at 5 p and the team will be the team that is playing in 8 p . if the team is playing at 4 p , and the team is playing p to win 5 p , what is the team that has the team playing p ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.compile(sampler=keras_nlp.samplers.TopKSampler(k=1))\n",
        "print(gpt2_lm.generate(\"I like basketball\", max_length=128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mono3vTR5g-N",
        "outputId": "c1d40c34-6720-41ba-a3ff-bb1d372b4046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like basketball is the least possible positive integer that is divisible by 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.compile(sampler=keras_nlp.samplers.TopKSampler(k=1))\n",
        "print(gpt2_lm.generate(\"I like basketball\", max_length=128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQGNmlHO5hWl",
        "outputId": "08cf28ee-5300-42c0-9435-55dd683a896f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like basketball is the least possible positive integer that is divisible by 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 ^ 2 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5 + 5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}